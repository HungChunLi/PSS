---
title: "R07_1_STM_topig_modeling"
author: "Jilung Hsieh"
date: "2019/6/5"
output:
  revealjs::revealjs_presentation:
    theme: solarized
    highlight: pygments
    center: true
    transition: fade
    reveal_options:
        slideNumber: true
        previewLinks: true
---
# understanding STM

- https://juliasilge.com/blog/sherlock-holmes-stm/





# Preparing environments
## importing libraries
```{r}
library(tidyverse)
library(stringr)
library(tidytext)
library(lubridate)
options(stringsAsFactors = F)
```


# stm Vignette
```{r}
# install.packages("stm")
library(stm)
data(package = "stm")
```

```{r}
str(poliblog5k.meta)
View(poliblog5k.docs)
```


## import jiebaR `cutter()`
- Defining your own preserved terms to a .R file and loading it when you need
- Defining Part-of-speech tagger by `tagger <- worker("tag")`

```{r}
library(jiebaR)
cutter <- worker()
segment_not <- c("韓國瑜")
# source("../segment_not.R") 
new_user_word(cutter, segment_not)
stopWords <- readRDS("data/stopWords.rds")
```

## Loading data
```{r}
load("pttdata/post_clean_df.rda")
str(post_clean_df)
```


# Preprocessing
## Tokenization

```{r}
unnested.df <- post_clean_df %>%
    mutate(line = row_number()) %>%
    filter(ptime > as.Date('2019-03-01'), 
           ptime < as.Date('2019-04-12')) %>%
    mutate(word = purrr::map(pcontent, function(x)segment(x, cutter))) %>% 
    unnest(word) %>%
    anti_join(stopWords) %>%
    filter(!str_detect(word, "[a-zA-Z0-9]+")) %>%
    filter(!is.na(word)) %>%
    group_by(word) %>%
    filter(n() > 5) %>%
    ungroup() %>%
    filter(nchar(word) > 1)
```


## Building dfm - Document-term matrix

```{r}
# install.packages("quanteda")
library(quanteda)

dfm <- unnested.df %>%
    count(plink, word, sort = TRUE) %>%
    cast_dfm(plink, word, n)
```


# Topic modeling
## STM

```{r}
# install.packages("stm")
library(stm)
topic_model <- stm(dfm, K = 12, init.type = "Spectral", reportevery = 10)
```

- <small>FREX weights words by their overall frequency and how exclusive they are to the topic (calculated as given in Equation 6).</small>
- Lift weights words by dividing by their frequency in other topics, therefore giving higher weight to words that appear less frequently in other topics. For more information on lift, see Taddy (2013). 
- Similar to lift, score divides the log frequency of the word in the topic by the log frequency of the word in other topics. For more information on score, see the lda R package, https://cran.r-project.org/package=lda. I

## Summary
```{r}
summary(topic_model)
print(topic_model)
```


## Advanced features
```{r}
mod.out.corr <- topicCorr(topic_model)
cloud(topic_model, topic = 7, scale = c(4,.5), family = "Heiti TC Light")
# install.packages("wordcloud")
plot(mod.out.corr)
mod.out.corr
```

## LDAvis
```{r}
# install.packages("LDAvis")
library(stm)
stm.doc <- quanteda::convert(dfm, to = "stm")
toLDAvis(topic_model, stm.doc$documents)
topics = c("韓粉", "初選民調", "責任期望", "香港深圳", 
                           "台聯辦", "九二共識", "報導留言", "農委會", "選舉",
                           "行程", "訪美演講", "譏諷韓粉")
```

## More features
```{r}
labelTopics(topic_model)
findThoughts(topic_model)
?toLDAvis
```


# STM with label
```{r}
news.df <- readRDS("data/typhoon.rds") %>%
    mutate(doc_id = row_number())
str(news.df)
news.df$cat <- as.factor(news.df$cat)
```

```{r}
segment_not <- c("第卅六條", "第卅八條", "蘇南成", "災前", "災後", "莫拉克", "颱風", "應變中心", "停班停課", "停課", "停班", "停駛", "路樹", "里長", "賀伯", "採收", "菜價", "蘇迪", "受災戶", "颱風警報", "韋恩", "台東縣", "馬總統", "豪大雨", "梅姬", "台東", "台北市政府", "工務段", "漂流木", "陳菊", "台南縣", "卡玫基", "魚塭", "救助金", "陳情", "全省", "強颱", "中颱", "輕颱", "小林村", "野溪", "蚵民", "農委會", "來襲", "中油公司", "蔣總統經國", "颱風天", "土石流", "蘇迪勒", "水利署", "陳說", "颱風假", "颱風地區", "台灣", "臺灣", "柯羅莎", "八八風災", "紓困","傅崑萁", "傅崐萁","台中", "文旦柚", "鄉鎮市公所", "鄉鎮市", "房屋稅", "高雄", "未達", "台灣省", "台北市")
cutter <- worker()
new_user_word(cutter, segment_not)
stopWords <- readRDS("data/stopWords.rds")

# load("../segment_not.R")
```


# Tokenization

```{r}
news.df$time %>% summary


tokenized.df <- news.df %>%
    mutate(timestamp=ymd(time)) %>% 
    # filter(timestamp > as.Date("2009-01-01")) %>%
    select(-time) %>%
    select(title, text, cat, timestamp, everything()) %>%
    mutate(word = purrr::map(text, function(x)segment(x, cutter)))

unnested.df <- tokenized.df %>%
    select(doc_id, text, word) %>%
    unnest(word) %>%
    filter(!(word %in% stopWords$word)) %>%
    filter(!str_detect(word, "[a-zA-Z0-9]+"))
```


## Building dfm
```{r}
dfm.typhoon <- unnested.df %>%
    count(doc_id, word, sort = TRUE) %>%
    cast_dfm(doc_id, word, n)
```

## STM
```{r}
# library(stm)
# 
# dfm_meta <- data.frame(doc_id = dfm.typhoon@Dimnames$docs) %>%
#     left_join(news.df %>% mutate(doc_id = as.character(doc_id)), by = c("doc_id"))


stm.doc <- quanteda::convert(dfm.typhoon, to = "stm")
stm.doc$meta <- data.frame(doc_id = names(stm.doc$documents)) %>%
    left_join(news.df %>% 
                  mutate(doc_id = as.character(doc_id)) %>% 
                  select(doc_id, cat), 
              by = c("doc_id"))

topic_model <- stm(dfm.typhoon, K = 12, 
                   prevalence =~ cat,
                   max.em.its = 75, data = dfm_meta,
                   init.type = "Spectral", reportevery = 10)
```

```{r}
plot(topic_model_meta, family = "Heiti TC Light")
summary(topic_model)
```

## with metadata again
```{r}
topic_model_meta <- stm(stm.doc$documents, stm.doc$vocab, K = 8,
                        prevalence =~ cat, 
                        content =~ cat,
                        max.em.its = 20, data = stm.doc$meta, init.type = "Spectral")
```


## Visualize

```{r}
plot(topic_model_meta, xlim = c(-.1, .1), type = "perspectives", 
     topics = 7, family = "Heiti TC Light")
```
```{r}

prep <- estimateEffect(1:8 ~ cat, topic_model_meta,
                       meta = stm.doc$meta, uncertainty = "Global")

plot(prep, covariate = "cat", topics = 1:8,
     model = topic_model_meta,
     cov.value1 = "catearly", cov.value2 = "catlat", 
     xlim = c(-0.1, 0.3))
```






